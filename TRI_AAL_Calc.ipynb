{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pluvial Representative Subset of Events\n",
    "\n",
    "__Description__:\n",
    "\n",
    "__Input__: \n",
    "\n",
    "__Output__: \n",
    "\n",
    "---\n",
    "## Load Libraries, Parameters, and File Paths:\n",
    "### Libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pathlib as pl\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters:\n",
    "#### Site specific:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "Project_Area = 'DC'\n",
    "\n",
    "root_dir = pl.Path(os.getcwd())\n",
    "inputs_dir = root_dir/f'Inputs/{Project_Area}'\n",
    "outputs_dir = root_dir/f'Outputs/{Project_Area}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Project specific (global):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "binwidth = 0.01       # [inches]; increment for binning the excess rainfall amount\n",
    "RI_max = 3000\n",
    "\n",
    "verbose = True        # Option to display print statements\n",
    "display_plots = True  # Option to display plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### File Paths:\n",
    "#### Weights:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "/home/sputnam/gitrepos/pfra-hydromet/Inputs/DC/DC_P03_D02_Weights.json\n/home/sputnam/gitrepos/pfra-hydromet/Inputs/DC/DC_P01_D01_Weights.json\n/home/sputnam/gitrepos/pfra-hydromet/Inputs/DC/DC_P04_D01_Weights.json\n/home/sputnam/gitrepos/pfra-hydromet/Inputs/DC/DC_P06_D01_Weights.json\n"
     ]
    }
   ],
   "source": [
    "weight_files = []\n",
    "for f in inputs_dir.glob('*.json'):\n",
    "    if 'Weights' in f.stem and 'TRI' not in f.stem: \n",
    "        weight_files.append(f)       \n",
    "        print(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Forcing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "/home/sputnam/gitrepos/pfra-hydromet/Inputs/DC/DC_P04_D01.json\n/home/sputnam/gitrepos/pfra-hydromet/Inputs/DC/DC_P06_D01.json\n/home/sputnam/gitrepos/pfra-hydromet/Inputs/DC/DC_P03_D01.json\n/home/sputnam/gitrepos/pfra-hydromet/Inputs/DC/DC_P01_D01.json\n/home/sputnam/gitrepos/pfra-hydromet/Inputs/DC/DC_P01_D02.json\n/home/sputnam/gitrepos/pfra-hydromet/Inputs/DC/DC_P06_D02.json\n/home/sputnam/gitrepos/pfra-hydromet/Inputs/DC/DC_P03_D02.json\n"
     ]
    }
   ],
   "source": [
    "forcing_files = []\n",
    "for f in inputs_dir.glob('**/*.json'):\n",
    "     if 'Weights' not in f.stem:\n",
    "        forcing_files.append(f)\n",
    "        print(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Calculate a Representative Subset of Events:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic = {}\n",
    "dic_vol = {}\n",
    "for forcing_file in forcing_files:\n",
    "    \n",
    "    _, Pluvial_Model, Domain = forcing_file.stem.split('_')\n",
    "    \n",
    "    for w in weight_files:\n",
    "        if Pluvial_Model in w.stem:\n",
    "            weight_file = w\n",
    "            \n",
    "    with open(forcing_file) as f:\n",
    "            ff_dic =  json.load(f)\n",
    "    \n",
    "    with open(weight_file) as f:\n",
    "            wt =  json.load(f)  \n",
    "            \n",
    "    mainBCN = list(wt['BCName'].keys())[0]\n",
    "    \n",
    "    df = pd.DataFrame()\n",
    "    df['Events'] = list(wt['BCName'][mainBCN].keys())\n",
    "    df['Weight'] = list(wt['BCName'][mainBCN].values())    \n",
    "    df = df.set_index('Events')\n",
    "    for d in list(ff_dic.keys()):\n",
    "        for k, v in ff_dic[d]['BCName'][Domain].items():\n",
    "            df.loc[k, 'Volume'] = sum(v)\n",
    "            df.loc[k, 'Dur'] = d\n",
    "    df = df.reset_index().sort_values(by=['Volume'], ascending = True).set_index('Events') \n",
    "    \n",
    "    binmin = min(df['Volume'])\n",
    "    binmax = max(df['Volume'])\n",
    "    bins = np.arange(binmin, binmax+binwidth, binwidth)\n",
    "    \n",
    "    lst = []\n",
    "    for i, b in enumerate(bins[:]):\n",
    "        if i==0:\n",
    "            weight = sum(df[(0.0 == df['Volume'])]['Weight'])\n",
    "        else:\n",
    "            weight = sum(df[(bins[i-1]  < df['Volume']) & (df['Volume']<=b)]['Weight'])\n",
    "        lst.append((b, weight))\n",
    "    \n",
    "    binned  = pd.DataFrame()\n",
    "    binned['Volume'] = [i[0] for i in lst]\n",
    "    binned['Weight'] = [i[1] for i in lst]\n",
    "    binned['Cumulative'] = binned['Weight'].cumsum()\n",
    "    binned['Theoretical RI'] = 1.0/(0.5-binned['Cumulative'])\n",
    "    \n",
    "    k = '{0}_{1}'.format(Pluvial_Model, Domain)\n",
    "    dic[k] = {}\n",
    "    dic_vol[k] = {}\n",
    "    for e in df.index: \n",
    "        vol = df.loc[e,'Volume']\n",
    "        dur = df.loc[e,'Dur']\n",
    "        ename = '{0}_{1}'.format(dur, e)\n",
    "        dic_vol[k][ename] = vol\n",
    "        if vol==0:\n",
    "            dic[k][ename] = min(round(binned.loc[0, 'Theoretical RI']), RI_max )\n",
    "        #elif vol==df['Volume'].max():\n",
    "        #    dic[k][ename] = binned.iloc[-2].loc['Theoretical RI']\n",
    "        else:\n",
    "            for j in binned.index[1:]:\n",
    "                v0 = binned.loc[j-1, 'Volume']\n",
    "                v1 = binned.loc[j, 'Volume']\n",
    "                if v0<vol<=v1:\n",
    "                    #dic[k][ename] = binned.loc[j, 'Theoretical RI']\n",
    "                    dic[k][ename] = min(round(binned.loc[j, 'Theoretical RI']), RI_max ) \n",
    "\n",
    "    # TTRI = binned.loc[0]['Theoretical RI']\n",
    "        \n",
    "    # if verbose:\n",
    "    #     print('{0} {1} Theoretical Threshold RI: {2} years'.format(Pluvial_Model, Domain, TTRI))\n",
    "        \n",
    "    # vavg = []\n",
    "    # for i, b in enumerate(binned['Volume']):\n",
    "    #     if i==0:\n",
    "    #         vavg.append(b)\n",
    "    #     elif i>0:\n",
    "    #         vavg.append((b+binned['Volume'][i-1])/2)\n",
    "    # binned['Vavg'] = vavg \n",
    "    \n",
    "    # event = []\n",
    "    # for vavg in binned['Vavg']:\n",
    "    #     diff = df['Volume']-vavg\n",
    "    #     event.append(diff[diff.abs().argsort()].index[0])\n",
    "    # binned['Event'] = event    \n",
    "    # binned.head()\n",
    "    \n",
    "    # unique_events = list(set(list(binned['Event'])))\n",
    "    # edf = pd.DataFrame(data = {'Event': unique_events})\n",
    "    # for i, e in enumerate(edf['Event']):\n",
    "    #     edf.loc[i, 'Weight'] = sum(binned[binned['Event']==e]['Weight']) \n",
    "    #     edf.loc[i, 'Volume'] = df.loc[e]['Volume']\n",
    "    # edf = edf[edf['Weight']>0.0].copy(deep=True)\n",
    "    # assert np.round(sum(edf['Weight']), 2) == 0.5 , 'Total weight does not equal 0.5 as expected'\n",
    "    # edf = edf.sort_values('Volume').reset_index(drop = True)\n",
    "    # edf['Cumulative'] = edf['Weight'].cumsum()\n",
    "    # print('Simulations to include in the Global Scale Test: {}'.format(edf.shape[0]))\n",
    "    \n",
    "    # fig, ax = plt.subplots(2, 1, figsize=(18, 12))\n",
    "    # ax[0].plot(df['Weight'], df['Volume'], linestyle = '', marker = '.' , label = 'All Events', color = 'gray', alpha = 0.75)\n",
    "    # ax[0].plot(edf['Weight'], edf['Volume'], linestyle = '', marker = '.', color = 'blue', label = 'Subset')\n",
    "    # ax[0].set_xlabel('Weight, [-]', fontsize = 10)\n",
    "    # ax[0].set_ylabel('Excess Rainfall, [inches]', fontsize=10)\n",
    "    # ax[0].set_xlim([0, 0.002])\n",
    "    # ax[0].legend()\n",
    "    # ax[0].grid()    \n",
    "    # ax[1].plot(binned['Volume'], 0.5 - binned['Cumulative'], linestyle = '-', marker = '', label = 'All Events', color = 'gray', alpha = 0.75)\n",
    "    # ax[1].plot(edf['Volume'], 0.5-edf['Cumulative'], linestyle = '-', marker = '', color = 'blue', label = 'Subset')\n",
    "    # ax[1].set_xlabel('Excess Rainfall, [inches]', fontsize = 10)\n",
    "    # ax[1].set_ylabel('Weight (~ probability)', fontsize=10)\n",
    "    # ax[1].legend()\n",
    "    # ax[1].grid()       \n",
    "    \n",
    "    # edic = {'BCName':{mainBCN:{}}}\n",
    "    # elist =  []\n",
    "    # for i, e in enumerate(edf['Event']):\n",
    "    #     edic['BCName'][mainBCN][e] = edf.loc[i]['Weight']\n",
    "    #     elist.append(e)\n",
    "    # with open(outputs_dir/'{0}_{1}_{2}_Weights_TRI.json'.format(Project_Area, Pluvial_Model, Domain), 'w') as f:\n",
    "    #     json.dump(edic, f)\n",
    "        \n",
    "    # df = pd.DataFrame(data = {'Events': elist})\n",
    "    # df = df.set_index('Events')\n",
    "    # df.to_csv(outputs_dir/'{0}_{1}_{2}_Events_TRI.csv'.format(Project_Area, Pluvial_Model, Domain))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = pd.ExcelWriter(outputs_dir/'{0}_Pluvial_TRI.xlsx'.format(Project_Area))\n",
    "for k in dic.keys():\n",
    "    tempdf = pd.DataFrame.from_dict(dic[k], orient='index', columns=['TRI'])\n",
    "    tempdf.index.name = 'Events'\n",
    "    for e in tempdf.index:\n",
    "        tempdf.loc[e, 'Volume'] = dic_vol[k][e]\n",
    "    tempdf['Dur'] = [x.split('_')[0] for x in tempdf.index]\n",
    "    tempdf = tempdf[tempdf['Dur']=='H24'].copy(deep=True)    \n",
    "    tempdf.sort_values('Volume', inplace = True)\n",
    "    tempdf.drop(columns=['Dur']).to_excel(writer, sheet_name = k)\n",
    "writer.save()    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "nteract": {
   "version": "0.15.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}