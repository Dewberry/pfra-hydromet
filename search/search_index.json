{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Documents Welcome to the pfra-hydromet documentation page! Tools Notebooks Execution enviornment for code. Core Core code called by notebooks.","title":"Home"},{"location":"#documents","text":"Welcome to the pfra-hydromet documentation page!","title":"Documents"},{"location":"#tools","text":"Notebooks Execution enviornment for code. Core Core code called by notebooks.","title":"Tools"},{"location":"CHANGELOG/","text":"Changelog 0.10.0 Public Release Tools in this repository were developed by Dewberry in its role as part of STARR II , a FEMA Production and Technical Services provider, to facilitate the automation of hydrologic computations for probabilistic flood risk studies. Computational approaches were developed in coordination with engineers at COMPASS , and guidance from engineers and scientists at FEMA , USACE , USGS , and NOAA . PrecipTable (Notebook) Download gridded data from NOAA Atlas 14 PFDS: User provides a vector polygon for Area of Interest (AOI) User provides selected storm durations Calculate average values within an AOI for: Mean precipitation Upper & lower confidence limits EventsTable (Notebook) Execute random event sampling using normal and lognormal distributions Randomly pair precipitation totals (volume) with temporal distributions (shape) to create a suite of events Performs convolution calculations to group like events based on volume and shape relationships Develop probabilities for paired events Write intermediate and metadata files to disk Core - Codebase for operations performed in notebooks.","title":"Changelog"},{"location":"CHANGELOG/#changelog","text":"","title":"Changelog"},{"location":"CHANGELOG/#0100","text":"Public Release Tools in this repository were developed by Dewberry in its role as part of STARR II , a FEMA Production and Technical Services provider, to facilitate the automation of hydrologic computations for probabilistic flood risk studies. Computational approaches were developed in coordination with engineers at COMPASS , and guidance from engineers and scientists at FEMA , USACE , USGS , and NOAA . PrecipTable (Notebook) Download gridded data from NOAA Atlas 14 PFDS: User provides a vector polygon for Area of Interest (AOI) User provides selected storm durations Calculate average values within an AOI for: Mean precipitation Upper & lower confidence limits EventsTable (Notebook) Execute random event sampling using normal and lognormal distributions Randomly pair precipitation totals (volume) with temporal distributions (shape) to create a suite of events Performs convolution calculations to group like events based on volume and shape relationships Develop probabilities for paired events Write intermediate and metadata files to disk Core - Codebase for operations performed in notebooks.","title":"0.10.0"},{"location":"CONTRIBUTING/","text":"Contributing If you would like to contribute code in the form of bug fixes, new features or other patches this page gives you more info on how to do so. Git Branching Model Dewberry follows the standard practice of using the master branch as the main integration branch. Git Commit Messages We follow the 'imperative present tense' style for commit messages. (e.g. \"Add gumbal distributions option to random sampler\") Issue Tracking If you find a bug and would like to report it please go there and create an issue. Pull Requests If you'd like to submit a code contribution please fork pfra-hydromet and send a pull request against the master branch. Like any other open source project, we might ask you to go through some iterations of discussion and refinement before merging. Editing these Docs Contributions to these docs are welcome as well. To build them on your own machine, ensure that MkDocs is installed.","title":"Contributing"},{"location":"CONTRIBUTING/#contributing","text":"If you would like to contribute code in the form of bug fixes, new features or other patches this page gives you more info on how to do so.","title":"Contributing"},{"location":"CONTRIBUTING/#git-branching-model","text":"Dewberry follows the standard practice of using the master branch as the main integration branch.","title":"Git Branching Model"},{"location":"CONTRIBUTING/#git-commit-messages","text":"We follow the 'imperative present tense' style for commit messages. (e.g. \"Add gumbal distributions option to random sampler\")","title":"Git Commit Messages"},{"location":"CONTRIBUTING/#issue-tracking","text":"If you find a bug and would like to report it please go there and create an issue.","title":"Issue Tracking"},{"location":"CONTRIBUTING/#pull-requests","text":"If you'd like to submit a code contribution please fork pfra-hydromet and send a pull request against the master branch. Like any other open source project, we might ask you to go through some iterations of discussion and refinement before merging.","title":"Pull Requests"},{"location":"CONTRIBUTING/#editing-these-docs","text":"Contributions to these docs are welcome as well. To build them on your own machine, ensure that MkDocs is installed.","title":"Editing these Docs"},{"location":"about/","text":"Overview Excess rainfall is calculated by first randomly selecting a precipitation recurrance interval and corresponding precipitation amount, precipitation temporal distribution, and curve number for the area of interest. The randomly selected precipitation data and curve number are then used by the curve number approach to calculate the excess rainfall amount for the corresponding recurrance interval. The procedure is repeated for the specified number of events/recurrance intervals. The incremental excess rainfall curves are grouped based on a novel test statistic that quantifies the incremental and cumulative volumentric differences between two curves. The mean of each group of curves is calculated and used in place of the original set of curves in order to improve modeling efficiency by reducing redundancy. Weights are assigned for each final event. Randomly Select Recurrance Intervals and Precipitation Amounts For each quartile of the precipitation temporal distributions: Randomly select precipitation recurrance intervals Calculate the expected value, lower confidence limit, and upper confidence limit for each recurrance interval Calculate the standard devation of the log-normal distribution using the lower/upper confidence limits at each recurrance interval Randomly select a precipitation amount from the calibrated log-normal distributuion at each recurrance interval Randomly pair event (precipitation total) with a decile Note: The decile number is randomly selected for each event, and each event is already associated with a quartile, therefore, given the quartile and the decile, the specific temporal distribution is assigned for each event. Randomly Select Curve Numbers Add the lower and upper values of the specified curve number to a table. Calculate the standard devation of the log-normal distribution for the curve number using the lower and upper values. Randomly select a curve number from the calibrated log-normal distributuion at each recurrance interval. Calculate Excess Rainfall Convert Excess Rainfall to Incremental To reduce the number of hydraulic simulations necssary, group like cuves in the next step Perform Convolution Tests Use a test statistic to evaluate shape and volume Test Statistic : Grouped Events Final Set of Events to Simulate","title":"About"},{"location":"about/#overview","text":"Excess rainfall is calculated by first randomly selecting a precipitation recurrance interval and corresponding precipitation amount, precipitation temporal distribution, and curve number for the area of interest. The randomly selected precipitation data and curve number are then used by the curve number approach to calculate the excess rainfall amount for the corresponding recurrance interval. The procedure is repeated for the specified number of events/recurrance intervals. The incremental excess rainfall curves are grouped based on a novel test statistic that quantifies the incremental and cumulative volumentric differences between two curves. The mean of each group of curves is calculated and used in place of the original set of curves in order to improve modeling efficiency by reducing redundancy. Weights are assigned for each final event.","title":"Overview"},{"location":"about/#randomly-select-recurrance-intervals-and-precipitation-amounts","text":"For each quartile of the precipitation temporal distributions: Randomly select precipitation recurrance intervals Calculate the expected value, lower confidence limit, and upper confidence limit for each recurrance interval Calculate the standard devation of the log-normal distribution using the lower/upper confidence limits at each recurrance interval Randomly select a precipitation amount from the calibrated log-normal distributuion at each recurrance interval","title":"Randomly Select Recurrance Intervals and Precipitation Amounts"},{"location":"about/#randomly-pair-event-precipitation-total-with-a-decile","text":"Note: The decile number is randomly selected for each event, and each event is already associated with a quartile, therefore, given the quartile and the decile, the specific temporal distribution is assigned for each event.","title":"Randomly pair event (precipitation total) with a decile"},{"location":"about/#randomly-select-curve-numbers","text":"Add the lower and upper values of the specified curve number to a table. Calculate the standard devation of the log-normal distribution for the curve number using the lower and upper values. Randomly select a curve number from the calibrated log-normal distributuion at each recurrance interval.","title":"Randomly Select Curve Numbers"},{"location":"about/#calculate-excess-rainfall","text":"","title":"Calculate Excess Rainfall"},{"location":"about/#convert-excess-rainfall-to-incremental","text":"To reduce the number of hydraulic simulations necssary, group like cuves in the next step","title":"Convert Excess Rainfall to Incremental"},{"location":"about/#perform-convolution-tests","text":"Use a test statistic to evaluate shape and volume Test Statistic :","title":"Perform Convolution Tests"},{"location":"about/#grouped-events","text":"","title":"Grouped Events"},{"location":"about/#final-set-of-events-to-simulate","text":"","title":"Final Set of Events to Simulate"},{"location":"core/","text":"hydromet : Core code for pfra-hydromet. hydromet_conv : Main function for convolution steps. hydromet_plotter : Plotting funcitons","title":"Core"},{"location":"hydromet/","text":"core.hydromet parse_filename parse_filename(zip_name:str, reg:str) -> dict Builds a dictionary with the region, recurrance interval, duration, and statistic type using the zip_name and region. get_masked_mean_atlas14 get_masked_mean_atlas14(gdf:'GeoDataFrame', raster:str) -> float Masks the Atlas 14 precipitation raster by the passed polygon and then calculates the average precipitation for the masked polygon. get_input_data get_input_data(precip_table_dir:str, duration:int, lower_limit:int=2, display_print:bool=True) -> pandas.core.frame.DataFrame Extracts the precipitation frequency data for the specified duration from an Excel sheet and returns the dataframe with the data. get_temporal_map get_temporal_map(data_dir:str, filename:str, vol:int, reg:int, dur:int, display_print:bool=True) -> dict Reads the json file containing the temporal distribution data metadata and returns the data map and number of rows to skip for the specified volume, region, and duration. get_temporals get_temporals(temporal_dir:str, vol:int, reg:int, dur:int, qmap:dict, display_print:bool=True) -> pandas.core.frame.DataFrame Reads the csv file containing the temporal distributions for the specified volume, region, and duration. Rows with NaNs for an index are dropped. Data was downloaded from: https://hdsc.nws.noaa.gov/hdsc/pfds/pfds_temporal.html get_quartile_rank get_quartile_rank(data_dir:str, filename:str, vol:int, reg:int, dur:int, display_print:bool=True) -> list Extracts the quartile ranks for the specified volume, region, and duration. The quartile rank corresponds to the percentage of precipitation events whose temporal distributions are represented by those in a specific quartile. get_duration_weight get_duration_weight(data_dir:str, filename:str, vol:int, reg:int, dur:int, display_print:bool=True) -> list Extracts the duration weight for the specified volume, region, and duration. The duration weight corresponds to the percentage of precipitation events with the specified duration. get_CN_distribution get_CN_distribution(data_dir:str, filename:str, CN:int, display_print:bool=True) -> dict Open the json file containing the curve number values for different antecedent moisture conditions and return the values for the specified curve number. extrap_add_ari extrap_add_ari(df:pandas.core.frame.DataFrame, display_print:bool=True) -> pandas.core.frame.DataFrame Calls the add_ari function to update the dataframe and then calls the extrapolate_extremes function in order to extrapolate the confidence limits and expected value of the precipitation amount for the 2000 and 3000 year return periods. add_ari add_ari(df:pandas.core.frame.DataFrame) -> pandas.core.frame.DataFrame Calculates the annual exceedance probability (AEP), average recurrance interval (ARI), and log of the ARI and adds the results to the original dataframe. extrapolate_extremes extrapolate_extremes(df:pandas.core.frame.DataFrame, rp:int, ycol:str) -> float Extrapolates the ycol for the specified return period. generate_random_samples generate_random_samples(samplesize:int, seed:int=None, display_print:bool=True) -> pandas.core.frame.DataFrame Selects the specified number of random samples from a continuous normal distribution, calculates the inverse of the sample, and saves the results in a dataframe with column \"Tr\", where \"Tr\" is the recurrance interval. Truncate_Random_Events Truncate_Random_Events(r_events:pandas.core.frame.DataFrame, lower_limit:int=2, upper_limit:int=3000) -> pandas.core.frame.DataFrame Removes events with recurrance intervals less than the lower_limit (typically 2 years) and sets recurrance intervals greater than the upper limit (typically 3000 years) eqaul to the upper limit. events_table_random events_table_random(raw_precip:pandas.core.frame.DataFrame, events_table:pandas.core.frame.DataFrame) -> pandas.core.frame.DataFrame Calls the add_ari function to update the dataframe and then calls the scipy_interp function in order calculate the expected value, lower (90%) confidence limits, and upper (90%) confidence limits for the events_table given the raw_precip dataframe. scipy_interp scipy_interp(raw_precip:pandas.core.frame.DataFrame, df:pandas.core.frame.DataFrame, ynew:str='Expected Value') -> pandas.core.frame.DataFrame Interpolates the ynew values for the passed df given the Log10_ARI and ynew valuea contained within the raw_precip dataframe. find_optimal_curve_std find_optimal_curve_std(df:pandas.core.frame.DataFrame, lower:str='Lower (90%)', upper:str='Upper (90%)', sdev:float=0.15) -> pandas.core.frame.DataFrame Calculates/optimizes the standard deviation of the lognormal distribution using the expected value, lower confidence limit/value, and the upper confidence limit/value. The sum of the squared residuals of the lower and upper confidence limits/values is used as the test statistic (this statistic is minimized). Note that the sdev is the initial estimate of the standard deviation. The fitted values should be compared to the lower and upper confidence limits/values to validate the optimization. Note: additional code exists at the end of the script containing this function which can be edited in order to improve the fit of the standard devation for CN. RandomizeData RandomizeData(df:pandas.core.frame.DataFrame, number:int, results_dir:str, AOI:str, duration:int=24, quartile:int=None, seed:int=None, sampling_distro:str='Lognorm', variable:str='Precipitation', lower:str='Lower (90%)', upper:str='Upper (90%)', plot:bool=False, display_print:bool=True) -> pandas.core.frame.DataFrame Randomly selects a value (precipitation or curve number) from the log- normal distribution given the expected value and optimized standard devation for each recurrance interval/event. join_rdata_tables join_rdata_tables(rdata_tables:list, type:str, display_print:bool=True) -> pandas.core.frame.DataFrame Concatenates the dataframe elements of the passed list producing a single dataframe. This resulting dataframe's index is set from 1 to the length of the dataframe. get_quartiles get_quartiles(raw_temporals:pandas.core.frame.DataFrame, dur:int, qrank:list, qmap:dict, vol:int, reg:int, plot:bool=False) -> dict For each quantile, extract the temporal data from the raw_temporals dataframe, convert the data to numeric, store the data in a dictionary, and plot the deciles. map_quartiles_deciles map_quartiles_deciles(n_samples:int=75, seed:int=None, plot:bool=False, display_print:bool=True) -> pandas.core.frame.DataFrame Constructs a dataframe containing randomly selected deciles for the specified number of samples (events). prep_cn_table prep_cn_table(CN:int, arc_data:dict) -> pandas.core.frame.DataFrame Constructs a dataframe with the average/expected curve number (CN), the dry/lower CN, and the wet/upper CN. The dry, average, and wet curve numbers refer to different antecedent runoff conditions, which were obtained from NEH Part 630, Chapter 10, Table 10-1 (https://www.wcc.nrcs.usda.gov/ftpref/wntsc/H&H/NEHhydrology/ch10.pdf) populate_event_precip_data populate_event_precip_data(random_cns:pandas.core.frame.DataFrame, temporals:pandas.core.frame.DataFrame, random_precip_table:pandas.core.frame.DataFrame, data_table:pandas.core.frame.DataFrame, curve_group:dict, dur:int=24, adjust_CN_less24:bool=False) -> (<class 'pandas.core.frame.DataFrame'>, <class 'pandas.core.frame.DataFrame'>, <class 'pandas.core.frame.DataFrame'>, <class 'pandas.core.frame.DataFrame'>) Calculates cumulative and incremental runoff for each event using a randomly selected precipitation amount, quartile specific temporal distribution, and curve number. update_CN update_CN(CN:int, duration:int, grid_avg_precip:float) -> (<class 'int'>, <class 'float'>, <class 'float'>) Adjusts the curve number (CN), potential maximum retention after runoff begins (S), and intial abstraction (Ia) for durations less than 24 hours. Contact Kaveh Zomorodi: kzomorodi@Dewberry.com for additional details regarding the adj_CN equation. S_24hr S_24hr(CN:int) -> float Calculates the potential maximum retention after runoff begins (S), in inches. IA_24hr IA_24hr(s24:float) -> float Calculats the inital abstraction (Ia) as a function of the maximum potentail rention (S). Lim et al. (2006) suggest that a 5% ratio of Ia to S is more appropriate for urbanized areas instead of the more commonly used 20% ratio (https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1752-1688.2006.tb04481.x). QCN_24hr QCN_24hr(grid_avg_precip:float, s24:float) -> float Calculates runoff using equation 10-11 of NEH Part 630, Chapter 10 (https://www.wcc.nrcs.usda.gov/ftpref/wntsc/H&H/NEHhydrology/ch10.pdf). infiltration_24hr infiltration_24hr(grid_avg_precip:float, s24:float, qcn_24:float) -> float Calculates the actual retention (or infilitration) after runoff begins, in inches using equation 10-7 of NEH Part 630, Chapter 10 (https://www.wcc.nrcs.usda.gov/ftpref/wntsc/H&H/NEHhydrology/ch10.pdf). calculate_excess calculate_excess(precip:float, ia:float, s:float) -> float Calculates runoff using the curve number approach. See equation 10-9 of NEH 630, Chapter 10 (https://www.wcc.nrcs.usda.gov/ftpref/wntsc/H&H/NEHhydrology/ch10.pdf) adjust_incremental adjust_incremental(raw:pandas.core.series.Series, excess:pandas.core.series.Series) -> pandas.core.series.Series Calculates the incremental runoff depth (depth/timestep) using the cumulative_to_incremental function, and then redistributes the first non-zero incremental runoff value over the prior timesteps using the incremental precipitation as a weighting function. cumulative_to_incremental cumulative_to_incremental(vector:pandas.core.series.Series) -> pandas.core.series.Series Converts the cumulative depth (precipitation or runoff) into the incremental depth, i.e. the depth/timestep (rate). convert_tempEpsilon convert_tempEpsilon(tempEpsilon:float, incr_excess:pandas.core.frame.DataFrame) -> int Converts the tempEpsilon from the number of hours to the number of corresponding timesteps. bin_sorting_dev bin_sorting_dev(incr_excess:pandas.core.frame.DataFrame, nbins:int, display_print:bool=True) -> list Computes the histogram of the series data with the specified number of bins and returns the results as a list. get_bin_slice get_bin_slice(incr_excess:pandas.core.frame.DataFrame, binstart:float, binstop:float) -> pandas.core.frame.DataFrame Slices the passed dataframe based on the events whose total runoff is bound by binstart and binstop. prep_data_for_convolution prep_data_for_convolution(dataslice:pandas.core.frame.DataFrame, adj_tempEpsilon:int) -> pandas.core.frame.DataFrame The runoff for each column (event) in the passed dataframe is calculated from zero to 24 hours for the intervals of length tempEpsilon*timstep (30 minutes). test_shapes test_shapes(dataslice:pandas.core.frame.DataFrame, col:str, adj_tempEpsilon:int) -> nptyping.Array Calculates the total runoff for each interval, where the interval width is equal to tempEpsilon times the timestep (30 minutes). conv_ts conv_ts(curve_test_df:pandas.core.frame.DataFrame, convEpsilon:float=150.0, volEpsilon:float=50.0) -> (<class 'dict'>, <class 'list'>) For each event combination, a test statistic is calculated in order to quantify the similarity between the two temporal distributions. Note that in this function's code, \"c\" and \"nc\" refer to \"column\" and \"next column\", respectively. test_stat test_stat(c_df:pandas.core.frame.DataFrame, nc_df:pandas.core.frame.DataFrame, c:str, nc:str, convEpsilon:float, volEpsilon:float) -> float Calculates a test statistic that quantifies the similarity between the two curves defined by \"c\" and \"nc\" within the passed dataframes. Note that in this function's code, \"c\" and \"nc\" refer to \"column\" and \"next column\", respectively. group_curves group_curves(test_dic:dict, test_values:list, events:list, test_stat_threshold:float=0.0) -> dict If the test statistic for a particular pair of events is greater than the threshold and neither of the events are already in a group, add them to a new group. Add all curves that are not a part of a group, to their own group. calc_mean_curves calc_mean_curves(curve_group:dict, dataslice:pandas.core.frame.DataFrame) -> pandas.core.frame.DataFrame Calculate the mean of the temporal distributions within each group. check_upd_curv check_upd_curv(all_groups:dict, updated_curves:pandas.core.frame.DataFrame, df:pandas.core.frame.DataFrame, convEpsilon:float, volEpsilon:float, test_stat_threshold:float) -> (<class 'dict'>, <class 'pandas.core.frame.DataFrame'>) The temporal distribution for each event within a group used to calculate a mean temporal distribution is compared to that mean temporal distribution using the same test statistic used to intially combine the distributions into groups. If the test statistic for that distribution is less than the test statistic threshold, the distribution and its corresponding subgroup are removed from the overall group used to calculate the mean curve. The subgroup and remainder of the original group are assigned to new, separate groups. Once all distributions have been checked against their mean distributions, the new groups are used to calculated updated mean distributions. extract_list extract_list(nested_list:list) -> list Extract all of the elements from the sublists within the list and return the elements as a list. map_curve_groups map_curve_groups(curve_group:dict, curve_group1:dict, ungroup:bool=False) -> dict Map the temporary event keys back to the orignal event IDs to keep a record of events within each group. renumber_dic_keys renumber_dic_keys(updated_group:dict, group_start_num:int) -> dict Renumber the dictionary keys so that they are ascending. final_test_stat final_test_stat(updated_group:dict, updated_curves:pandas.core.frame.DataFrame, df:pandas.core.frame.DataFrame, convEpsilon:float, volEpsilon:float) -> dict For each group of distributions, the test statistic for each temporal distribution and corresponding mean temporal distribution (the group average) is calculated. dic_to_list dic_to_list(dic:dict, get_set:bool=False) -> list Extracts the values from each key within a dictionary and returns the values as a single list. Calc_Group_Weight Calc_Group_Weight(final_groups:dict, duration_weight:float, display_print:bool=True) -> dict Calculates the weight of each group of curves, such that the sum of all the weights adds to the duration_weight. Rename_Final_Groups Rename_Final_Groups(curve_weight:dict, dur:int) -> dict Sorts the groups by their weight and then renames the groups so that the group with the largest weight is designed E0001 and the group with the next largest weight is designated E0002 (for the 6 hour duration). The thounsands place is set to 0, 1, 2, 3 for the 6, 12, 24, and 96 hour durations, respectively. A dictionary mapping the original group names to the new group names is returned. dic_key_to_str dic_key_to_str(orig_dic:dict) -> dict Converts the keys of the passed dictionary to strings.","title":"core.hydromet"},{"location":"hydromet/#corehydromet","text":"","title":"core.hydromet"},{"location":"hydromet/#parse_filename","text":"parse_filename(zip_name:str, reg:str) -> dict Builds a dictionary with the region, recurrance interval, duration, and statistic type using the zip_name and region.","title":"parse_filename"},{"location":"hydromet/#get_masked_mean_atlas14","text":"get_masked_mean_atlas14(gdf:'GeoDataFrame', raster:str) -> float Masks the Atlas 14 precipitation raster by the passed polygon and then calculates the average precipitation for the masked polygon.","title":"get_masked_mean_atlas14"},{"location":"hydromet/#get_input_data","text":"get_input_data(precip_table_dir:str, duration:int, lower_limit:int=2, display_print:bool=True) -> pandas.core.frame.DataFrame Extracts the precipitation frequency data for the specified duration from an Excel sheet and returns the dataframe with the data.","title":"get_input_data"},{"location":"hydromet/#get_temporal_map","text":"get_temporal_map(data_dir:str, filename:str, vol:int, reg:int, dur:int, display_print:bool=True) -> dict Reads the json file containing the temporal distribution data metadata and returns the data map and number of rows to skip for the specified volume, region, and duration.","title":"get_temporal_map"},{"location":"hydromet/#get_temporals","text":"get_temporals(temporal_dir:str, vol:int, reg:int, dur:int, qmap:dict, display_print:bool=True) -> pandas.core.frame.DataFrame Reads the csv file containing the temporal distributions for the specified volume, region, and duration. Rows with NaNs for an index are dropped. Data was downloaded from: https://hdsc.nws.noaa.gov/hdsc/pfds/pfds_temporal.html","title":"get_temporals"},{"location":"hydromet/#get_quartile_rank","text":"get_quartile_rank(data_dir:str, filename:str, vol:int, reg:int, dur:int, display_print:bool=True) -> list Extracts the quartile ranks for the specified volume, region, and duration. The quartile rank corresponds to the percentage of precipitation events whose temporal distributions are represented by those in a specific quartile.","title":"get_quartile_rank"},{"location":"hydromet/#get_duration_weight","text":"get_duration_weight(data_dir:str, filename:str, vol:int, reg:int, dur:int, display_print:bool=True) -> list Extracts the duration weight for the specified volume, region, and duration. The duration weight corresponds to the percentage of precipitation events with the specified duration.","title":"get_duration_weight"},{"location":"hydromet/#get_cn_distribution","text":"get_CN_distribution(data_dir:str, filename:str, CN:int, display_print:bool=True) -> dict Open the json file containing the curve number values for different antecedent moisture conditions and return the values for the specified curve number.","title":"get_CN_distribution"},{"location":"hydromet/#extrap_add_ari","text":"extrap_add_ari(df:pandas.core.frame.DataFrame, display_print:bool=True) -> pandas.core.frame.DataFrame Calls the add_ari function to update the dataframe and then calls the extrapolate_extremes function in order to extrapolate the confidence limits and expected value of the precipitation amount for the 2000 and 3000 year return periods.","title":"extrap_add_ari"},{"location":"hydromet/#add_ari","text":"add_ari(df:pandas.core.frame.DataFrame) -> pandas.core.frame.DataFrame Calculates the annual exceedance probability (AEP), average recurrance interval (ARI), and log of the ARI and adds the results to the original dataframe.","title":"add_ari"},{"location":"hydromet/#extrapolate_extremes","text":"extrapolate_extremes(df:pandas.core.frame.DataFrame, rp:int, ycol:str) -> float Extrapolates the ycol for the specified return period.","title":"extrapolate_extremes"},{"location":"hydromet/#generate_random_samples","text":"generate_random_samples(samplesize:int, seed:int=None, display_print:bool=True) -> pandas.core.frame.DataFrame Selects the specified number of random samples from a continuous normal distribution, calculates the inverse of the sample, and saves the results in a dataframe with column \"Tr\", where \"Tr\" is the recurrance interval.","title":"generate_random_samples"},{"location":"hydromet/#truncate_random_events","text":"Truncate_Random_Events(r_events:pandas.core.frame.DataFrame, lower_limit:int=2, upper_limit:int=3000) -> pandas.core.frame.DataFrame Removes events with recurrance intervals less than the lower_limit (typically 2 years) and sets recurrance intervals greater than the upper limit (typically 3000 years) eqaul to the upper limit.","title":"Truncate_Random_Events"},{"location":"hydromet/#events_table_random","text":"events_table_random(raw_precip:pandas.core.frame.DataFrame, events_table:pandas.core.frame.DataFrame) -> pandas.core.frame.DataFrame Calls the add_ari function to update the dataframe and then calls the scipy_interp function in order calculate the expected value, lower (90%) confidence limits, and upper (90%) confidence limits for the events_table given the raw_precip dataframe.","title":"events_table_random"},{"location":"hydromet/#scipy_interp","text":"scipy_interp(raw_precip:pandas.core.frame.DataFrame, df:pandas.core.frame.DataFrame, ynew:str='Expected Value') -> pandas.core.frame.DataFrame Interpolates the ynew values for the passed df given the Log10_ARI and ynew valuea contained within the raw_precip dataframe.","title":"scipy_interp"},{"location":"hydromet/#find_optimal_curve_std","text":"find_optimal_curve_std(df:pandas.core.frame.DataFrame, lower:str='Lower (90%)', upper:str='Upper (90%)', sdev:float=0.15) -> pandas.core.frame.DataFrame Calculates/optimizes the standard deviation of the lognormal distribution using the expected value, lower confidence limit/value, and the upper confidence limit/value. The sum of the squared residuals of the lower and upper confidence limits/values is used as the test statistic (this statistic is minimized). Note that the sdev is the initial estimate of the standard deviation. The fitted values should be compared to the lower and upper confidence limits/values to validate the optimization. Note: additional code exists at the end of the script containing this function which can be edited in order to improve the fit of the standard devation for CN.","title":"find_optimal_curve_std"},{"location":"hydromet/#randomizedata","text":"RandomizeData(df:pandas.core.frame.DataFrame, number:int, results_dir:str, AOI:str, duration:int=24, quartile:int=None, seed:int=None, sampling_distro:str='Lognorm', variable:str='Precipitation', lower:str='Lower (90%)', upper:str='Upper (90%)', plot:bool=False, display_print:bool=True) -> pandas.core.frame.DataFrame Randomly selects a value (precipitation or curve number) from the log- normal distribution given the expected value and optimized standard devation for each recurrance interval/event.","title":"RandomizeData"},{"location":"hydromet/#join_rdata_tables","text":"join_rdata_tables(rdata_tables:list, type:str, display_print:bool=True) -> pandas.core.frame.DataFrame Concatenates the dataframe elements of the passed list producing a single dataframe. This resulting dataframe's index is set from 1 to the length of the dataframe.","title":"join_rdata_tables"},{"location":"hydromet/#get_quartiles","text":"get_quartiles(raw_temporals:pandas.core.frame.DataFrame, dur:int, qrank:list, qmap:dict, vol:int, reg:int, plot:bool=False) -> dict For each quantile, extract the temporal data from the raw_temporals dataframe, convert the data to numeric, store the data in a dictionary, and plot the deciles.","title":"get_quartiles"},{"location":"hydromet/#map_quartiles_deciles","text":"map_quartiles_deciles(n_samples:int=75, seed:int=None, plot:bool=False, display_print:bool=True) -> pandas.core.frame.DataFrame Constructs a dataframe containing randomly selected deciles for the specified number of samples (events).","title":"map_quartiles_deciles"},{"location":"hydromet/#prep_cn_table","text":"prep_cn_table(CN:int, arc_data:dict) -> pandas.core.frame.DataFrame Constructs a dataframe with the average/expected curve number (CN), the dry/lower CN, and the wet/upper CN. The dry, average, and wet curve numbers refer to different antecedent runoff conditions, which were obtained from NEH Part 630, Chapter 10, Table 10-1 (https://www.wcc.nrcs.usda.gov/ftpref/wntsc/H&H/NEHhydrology/ch10.pdf)","title":"prep_cn_table"},{"location":"hydromet/#populate_event_precip_data","text":"populate_event_precip_data(random_cns:pandas.core.frame.DataFrame, temporals:pandas.core.frame.DataFrame, random_precip_table:pandas.core.frame.DataFrame, data_table:pandas.core.frame.DataFrame, curve_group:dict, dur:int=24, adjust_CN_less24:bool=False) -> (<class 'pandas.core.frame.DataFrame'>, <class 'pandas.core.frame.DataFrame'>, <class 'pandas.core.frame.DataFrame'>, <class 'pandas.core.frame.DataFrame'>) Calculates cumulative and incremental runoff for each event using a randomly selected precipitation amount, quartile specific temporal distribution, and curve number.","title":"populate_event_precip_data"},{"location":"hydromet/#update_cn","text":"update_CN(CN:int, duration:int, grid_avg_precip:float) -> (<class 'int'>, <class 'float'>, <class 'float'>) Adjusts the curve number (CN), potential maximum retention after runoff begins (S), and intial abstraction (Ia) for durations less than 24 hours. Contact Kaveh Zomorodi: kzomorodi@Dewberry.com for additional details regarding the adj_CN equation.","title":"update_CN"},{"location":"hydromet/#s_24hr","text":"S_24hr(CN:int) -> float Calculates the potential maximum retention after runoff begins (S), in inches.","title":"S_24hr"},{"location":"hydromet/#ia_24hr","text":"IA_24hr(s24:float) -> float Calculats the inital abstraction (Ia) as a function of the maximum potentail rention (S). Lim et al. (2006) suggest that a 5% ratio of Ia to S is more appropriate for urbanized areas instead of the more commonly used 20% ratio (https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1752-1688.2006.tb04481.x).","title":"IA_24hr"},{"location":"hydromet/#qcn_24hr","text":"QCN_24hr(grid_avg_precip:float, s24:float) -> float Calculates runoff using equation 10-11 of NEH Part 630, Chapter 10 (https://www.wcc.nrcs.usda.gov/ftpref/wntsc/H&H/NEHhydrology/ch10.pdf).","title":"QCN_24hr"},{"location":"hydromet/#infiltration_24hr","text":"infiltration_24hr(grid_avg_precip:float, s24:float, qcn_24:float) -> float Calculates the actual retention (or infilitration) after runoff begins, in inches using equation 10-7 of NEH Part 630, Chapter 10 (https://www.wcc.nrcs.usda.gov/ftpref/wntsc/H&H/NEHhydrology/ch10.pdf).","title":"infiltration_24hr"},{"location":"hydromet/#calculate_excess","text":"calculate_excess(precip:float, ia:float, s:float) -> float Calculates runoff using the curve number approach. See equation 10-9 of NEH 630, Chapter 10 (https://www.wcc.nrcs.usda.gov/ftpref/wntsc/H&H/NEHhydrology/ch10.pdf)","title":"calculate_excess"},{"location":"hydromet/#adjust_incremental","text":"adjust_incremental(raw:pandas.core.series.Series, excess:pandas.core.series.Series) -> pandas.core.series.Series Calculates the incremental runoff depth (depth/timestep) using the cumulative_to_incremental function, and then redistributes the first non-zero incremental runoff value over the prior timesteps using the incremental precipitation as a weighting function.","title":"adjust_incremental"},{"location":"hydromet/#cumulative_to_incremental","text":"cumulative_to_incremental(vector:pandas.core.series.Series) -> pandas.core.series.Series Converts the cumulative depth (precipitation or runoff) into the incremental depth, i.e. the depth/timestep (rate).","title":"cumulative_to_incremental"},{"location":"hydromet/#convert_tempepsilon","text":"convert_tempEpsilon(tempEpsilon:float, incr_excess:pandas.core.frame.DataFrame) -> int Converts the tempEpsilon from the number of hours to the number of corresponding timesteps.","title":"convert_tempEpsilon"},{"location":"hydromet/#bin_sorting_dev","text":"bin_sorting_dev(incr_excess:pandas.core.frame.DataFrame, nbins:int, display_print:bool=True) -> list Computes the histogram of the series data with the specified number of bins and returns the results as a list.","title":"bin_sorting_dev"},{"location":"hydromet/#get_bin_slice","text":"get_bin_slice(incr_excess:pandas.core.frame.DataFrame, binstart:float, binstop:float) -> pandas.core.frame.DataFrame Slices the passed dataframe based on the events whose total runoff is bound by binstart and binstop.","title":"get_bin_slice"},{"location":"hydromet/#prep_data_for_convolution","text":"prep_data_for_convolution(dataslice:pandas.core.frame.DataFrame, adj_tempEpsilon:int) -> pandas.core.frame.DataFrame The runoff for each column (event) in the passed dataframe is calculated from zero to 24 hours for the intervals of length tempEpsilon*timstep (30 minutes).","title":"prep_data_for_convolution"},{"location":"hydromet/#test_shapes","text":"test_shapes(dataslice:pandas.core.frame.DataFrame, col:str, adj_tempEpsilon:int) -> nptyping.Array Calculates the total runoff for each interval, where the interval width is equal to tempEpsilon times the timestep (30 minutes).","title":"test_shapes"},{"location":"hydromet/#conv_ts","text":"conv_ts(curve_test_df:pandas.core.frame.DataFrame, convEpsilon:float=150.0, volEpsilon:float=50.0) -> (<class 'dict'>, <class 'list'>) For each event combination, a test statistic is calculated in order to quantify the similarity between the two temporal distributions. Note that in this function's code, \"c\" and \"nc\" refer to \"column\" and \"next column\", respectively.","title":"conv_ts"},{"location":"hydromet/#test_stat","text":"test_stat(c_df:pandas.core.frame.DataFrame, nc_df:pandas.core.frame.DataFrame, c:str, nc:str, convEpsilon:float, volEpsilon:float) -> float Calculates a test statistic that quantifies the similarity between the two curves defined by \"c\" and \"nc\" within the passed dataframes. Note that in this function's code, \"c\" and \"nc\" refer to \"column\" and \"next column\", respectively.","title":"test_stat"},{"location":"hydromet/#group_curves","text":"group_curves(test_dic:dict, test_values:list, events:list, test_stat_threshold:float=0.0) -> dict If the test statistic for a particular pair of events is greater than the threshold and neither of the events are already in a group, add them to a new group. Add all curves that are not a part of a group, to their own group.","title":"group_curves"},{"location":"hydromet/#calc_mean_curves","text":"calc_mean_curves(curve_group:dict, dataslice:pandas.core.frame.DataFrame) -> pandas.core.frame.DataFrame Calculate the mean of the temporal distributions within each group.","title":"calc_mean_curves"},{"location":"hydromet/#check_upd_curv","text":"check_upd_curv(all_groups:dict, updated_curves:pandas.core.frame.DataFrame, df:pandas.core.frame.DataFrame, convEpsilon:float, volEpsilon:float, test_stat_threshold:float) -> (<class 'dict'>, <class 'pandas.core.frame.DataFrame'>) The temporal distribution for each event within a group used to calculate a mean temporal distribution is compared to that mean temporal distribution using the same test statistic used to intially combine the distributions into groups. If the test statistic for that distribution is less than the test statistic threshold, the distribution and its corresponding subgroup are removed from the overall group used to calculate the mean curve. The subgroup and remainder of the original group are assigned to new, separate groups. Once all distributions have been checked against their mean distributions, the new groups are used to calculated updated mean distributions.","title":"check_upd_curv"},{"location":"hydromet/#extract_list","text":"extract_list(nested_list:list) -> list Extract all of the elements from the sublists within the list and return the elements as a list.","title":"extract_list"},{"location":"hydromet/#map_curve_groups","text":"map_curve_groups(curve_group:dict, curve_group1:dict, ungroup:bool=False) -> dict Map the temporary event keys back to the orignal event IDs to keep a record of events within each group.","title":"map_curve_groups"},{"location":"hydromet/#renumber_dic_keys","text":"renumber_dic_keys(updated_group:dict, group_start_num:int) -> dict Renumber the dictionary keys so that they are ascending.","title":"renumber_dic_keys"},{"location":"hydromet/#final_test_stat","text":"final_test_stat(updated_group:dict, updated_curves:pandas.core.frame.DataFrame, df:pandas.core.frame.DataFrame, convEpsilon:float, volEpsilon:float) -> dict For each group of distributions, the test statistic for each temporal distribution and corresponding mean temporal distribution (the group average) is calculated.","title":"final_test_stat"},{"location":"hydromet/#dic_to_list","text":"dic_to_list(dic:dict, get_set:bool=False) -> list Extracts the values from each key within a dictionary and returns the values as a single list.","title":"dic_to_list"},{"location":"hydromet/#calc_group_weight","text":"Calc_Group_Weight(final_groups:dict, duration_weight:float, display_print:bool=True) -> dict Calculates the weight of each group of curves, such that the sum of all the weights adds to the duration_weight.","title":"Calc_Group_Weight"},{"location":"hydromet/#rename_final_groups","text":"Rename_Final_Groups(curve_weight:dict, dur:int) -> dict Sorts the groups by their weight and then renames the groups so that the group with the largest weight is designed E0001 and the group with the next largest weight is designated E0002 (for the 6 hour duration). The thounsands place is set to 0, 1, 2, 3 for the 6, 12, 24, and 96 hour durations, respectively. A dictionary mapping the original group names to the new group names is returned.","title":"Rename_Final_Groups"},{"location":"hydromet/#dic_key_to_str","text":"dic_key_to_str(orig_dic:dict) -> dict Converts the keys of the passed dictionary to strings.","title":"dic_key_to_str"},{"location":"hydromet_conv/","text":"core core.hydromet_conv main main(binData:list, incr_excess:pandas.core.frame.DataFrame, tempE:float, convE:float, volE:float, tsthresh:float, display_print:bool=True) -> dict Function for grouping incremental excess rainfall curves using a novel test statistic that quantifies the incremental and cumulative volumentric differences between two curves. The mean of each group of curves is calculated and used in place of the original set of curves in order to improve modeling efficiency by reducing redundancy.","title":"core"},{"location":"hydromet_conv/#core","text":"","title":"core"},{"location":"hydromet_conv/#corehydromet_conv","text":"","title":"core.hydromet_conv"},{"location":"hydromet_conv/#main","text":"main(binData:list, incr_excess:pandas.core.frame.DataFrame, tempE:float, convE:float, volE:float, tsthresh:float, display_print:bool=True) -> dict Function for grouping incremental excess rainfall curves using a novel test statistic that quantifies the incremental and cumulative volumentric differences between two curves. The mean of each group of curves is calculated and used in place of the original set of curves in order to improve modeling efficiency by reducing redundancy.","title":"main"},{"location":"hydromet_plotter/","text":"","title":"Hydromet plotter"},{"location":"quickstart/","text":"Overview of tools: Example input and output parameters/files. Example Inputs filenames and paths for the precipitation frequency table, DataRepository, and location to save the outputs. Vector File covering area of interest (hydraulic domain). NOAA data Atlas 14 Volume number, region, and duration. CN Curve Number calaculated for the area of interest. Convolution Parameters (*epsilons) tempEpsilon The number of hours over which to resample the incremental excess rainfall during the first convolution. tempEpsilon2 The number of hours over which to resample the incremental excess rainfall during the final convolution. convEpsilon The maximum allowable percent difference in incremental excess between two event at any given resampled timestep. volEpsilon The maximum allowable percent difference between the two events total runoff volume. * Suggested epsilon values are given. Epsilon values should be adapted for each project area by analyzing the curve fitting results. Plots can be shown for every group by setting display_plots=True Optional Features Check functions for defalut options for using a known seed, testing, debuggging, etc. (e.g. seed=88 ) Example Outputs PrecipTable Precipitation Frequency estimates for AOI. Tr Lower 90% Expected Value Upper 90% 2 5.25 6.32 7.60 5 6.85 8.27 9.96 10 8.20 9.95 12.05 25 10.06 12.45 15.86 50 11.48 14.56 18.75 100 12.85 16.86 22.22 200 14.20 19.33 26.19 500 16.20 22.89 31.84 1000 17.71 25.79 36.11 Random Events Table Randomly chosen events & metadata before convolution. Return Period Ann. Exc. Prob. ARI Log10_ARI Expected Value Lower (90%) Upper (90%) Quartile Sigma Fitted Lower (90%) Limit Fitted Upper (90%) Limit Random Precipitation 2.000240382 0.499939912 1.442945202 0.366686304 3.15751785 2.876612547 3.507262528 3 0.078317368 2.855989829 3.49088042 3.308578113 2.001189958 0.499702687 1.44393337 0.367370897 3.157996455 2.877045943 3.507791811 3 0.078224163 2.856763942 3.490992541 3.331452983 2.00267425 0.49933233 1.445477879 0.368439979 3.158744005 2.877722879 3.508618516 3 0.078224124 2.857440325 3.491818745 3.453517084 ... ... ... ... ... ... ... ... ... ... ... ... 923.2492014 0.001083131 922.749111 6.827357379 13.55155136 11.4917289 14.67457848 3 0.087869372 12.10830888 15.16682025 12.88399871 1119.173615 0.000893516 1118.67354 7.019898923 14.11398151 11.92280701 15.27555124 3 0.088696172 12.59748493 15.81303532 14.49259104 3000 0.000333333 2999.499972 8.006200878 17.38236261 14.3978362 18.76211492 3 0.092819505 15.43292272 19.57804981 18.76211492 Curve Number Table Randomly chosen CN number and metadata. Random Sample Lower Expected Value Upper Sigma Fitted Lower Limit Fitted Upper Limit Random CN 1 67 83 93 0.116325785 71.50469526 96.34332368 88 2 67 83 93 0.116325785 71.50469526 96.34332368 89 3 67 83 93 0.116325785 71.50469526 96.34332368 93 ... ... ... ... ... ... ... ... 5107 67 83 93 0.116325785 71.50469526 96.34332368 90 5108 67 83 93 0.116325785 71.50469526 96.34332368 87 5109 67 83 93 0.116325785 71.50469526 96.34332368 93 Final Events Table Final events to be modeled. hours E0001 E0002 E0003 ... E0395 E0396 E0397 E0398 E0399 0 0 0 0 ... 0 0 0 0 0 0.5 0.010 0.0047 0.0030 ... 0.01359 0.01038 0.00674 0.00234 0.00555 1 0.013 0.00948 0.0043 ... 0.0447 0.0584 0.0124 0.00356 0.008906 1.5 0.10 0.067680 0.0294 ... 0.1660 0.15102 0.1220 0.0198 0.0433 ... ... ... ... ... ... ... ... ... ... 22 0.13 0.1534 0.0807 ... 0.1878 0.1707 0.234 0.07389 0.149328 23.5 0.103 0.21576 0.14100 ... 0.1373 0.1408 0.317 0.15162 0.221391 24 0.08732 0.25004 0.1836 ... 0.1132 0.1293 0.3403 0.2053 0.2430 Event Weight Table Weight E0001 0.006207654 E0002 0.005313752 ... ... E0964 0.000019172 E0965 0.000071544 Metada Additional data developed in intermediated calculations included for traceability/reporducibility. [{ # Run Data (Event_Duration_Quartile_Decile_CurveNumber) 'RunInfo': {'E60001': 'E1_6Hr_Q1_D10_CN79', 'E60002': 'E2_6Hr_Q1_D90_CN78', ...} # Cumulative (raw) precipitation time-series 'precip': {'E60001': {'0.0': 0.0, '0.5': 0.8010830472988398, '1.0': 1.4541398793359375, '1.5': 1.8372665541310351, '2.0': 2.057129020916858, '2.5': 2.1550875457224223, '3.0': 2.170325538469955, '3.5': 2.176856106790326, '4.0': 2.176856106790326, '4.5': 2.176856106790326, '5.0': 2.176856106790326, '5.5': 2.176856106790326, '6.0': 2.176856106790326}, 'E60002': { ... } # Cumulative excess-precipitation time-series 'cum_excess': {'E60001': {'0.0': 0.0, '0.5': 0.02479673948334961, '1.0': 0.23766036959891948, '1.5': 0.4300482251417235, '2.0': 0.5562285716308201, '2.5': 0.6155457935761868, '3.0': 0.6249312656222388, '3.5': 0.6289662984090281, '4.0': 0.6289662984090281, '4.5': 0.6289662984090281, '5.0': 0.6289662984090281, '5.5': 0.6289662984090281, '6.0': 0.6289662984090281}, 'E60002': { ... } # Incremental excess-precipitation time-series 'incr_excess' {'E60001': {'0.0': 0.0, '0.5': 0.02479673948334961, '1.0': 0.21286363011556986, '1.5': 0.19238785554280402, '2.0': 0.1261803464890966, '2.5': 0.059317221945366705, '3.0': 0.009385472046052001, '3.5': 0.004035032786789294, '4.0': 0.0, '4.5': 0.0, '5.0': 0.0, '5.5': 0.0, '6.0': 0.0}, 'E60002': { ... } # Curve groups (similar excess-precipitation time-series) 'groups' {'E0001': ['E60002', 'E60930', 'E60551', ... , E64421', E64423', 'E64483'], 'E0002': [... ] } # Test Statistic 'test_stat' {'E0001': [0.235358, 0.251304, 0.214125, ... 0.18715, 0.184935, 0.174473], 'E0002': [... ] }]","title":"Quickstart"},{"location":"quickstart/#overview-of-tools","text":"Example input and output parameters/files.","title":"Overview of tools:"},{"location":"quickstart/#example-inputs","text":"filenames and paths for the precipitation frequency table, DataRepository, and location to save the outputs. Vector File covering area of interest (hydraulic domain). NOAA data Atlas 14 Volume number, region, and duration. CN Curve Number calaculated for the area of interest.","title":"Example Inputs"},{"location":"quickstart/#convolution-parameters-epsilons","text":"tempEpsilon The number of hours over which to resample the incremental excess rainfall during the first convolution. tempEpsilon2 The number of hours over which to resample the incremental excess rainfall during the final convolution. convEpsilon The maximum allowable percent difference in incremental excess between two event at any given resampled timestep. volEpsilon The maximum allowable percent difference between the two events total runoff volume. * Suggested epsilon values are given. Epsilon values should be adapted for each project area by analyzing the curve fitting results. Plots can be shown for every group by setting display_plots=True","title":"Convolution Parameters (*epsilons)"},{"location":"quickstart/#optional-features","text":"Check functions for defalut options for using a known seed, testing, debuggging, etc. (e.g. seed=88 )","title":"Optional Features"},{"location":"quickstart/#example-outputs","text":"","title":"Example Outputs"},{"location":"quickstart/#preciptable","text":"Precipitation Frequency estimates for AOI. Tr Lower 90% Expected Value Upper 90% 2 5.25 6.32 7.60 5 6.85 8.27 9.96 10 8.20 9.95 12.05 25 10.06 12.45 15.86 50 11.48 14.56 18.75 100 12.85 16.86 22.22 200 14.20 19.33 26.19 500 16.20 22.89 31.84 1000 17.71 25.79 36.11","title":"PrecipTable"},{"location":"quickstart/#random-events-table","text":"Randomly chosen events & metadata before convolution. Return Period Ann. Exc. Prob. ARI Log10_ARI Expected Value Lower (90%) Upper (90%) Quartile Sigma Fitted Lower (90%) Limit Fitted Upper (90%) Limit Random Precipitation 2.000240382 0.499939912 1.442945202 0.366686304 3.15751785 2.876612547 3.507262528 3 0.078317368 2.855989829 3.49088042 3.308578113 2.001189958 0.499702687 1.44393337 0.367370897 3.157996455 2.877045943 3.507791811 3 0.078224163 2.856763942 3.490992541 3.331452983 2.00267425 0.49933233 1.445477879 0.368439979 3.158744005 2.877722879 3.508618516 3 0.078224124 2.857440325 3.491818745 3.453517084 ... ... ... ... ... ... ... ... ... ... ... ... 923.2492014 0.001083131 922.749111 6.827357379 13.55155136 11.4917289 14.67457848 3 0.087869372 12.10830888 15.16682025 12.88399871 1119.173615 0.000893516 1118.67354 7.019898923 14.11398151 11.92280701 15.27555124 3 0.088696172 12.59748493 15.81303532 14.49259104 3000 0.000333333 2999.499972 8.006200878 17.38236261 14.3978362 18.76211492 3 0.092819505 15.43292272 19.57804981 18.76211492","title":"Random Events Table"},{"location":"quickstart/#curve-number-table","text":"Randomly chosen CN number and metadata. Random Sample Lower Expected Value Upper Sigma Fitted Lower Limit Fitted Upper Limit Random CN 1 67 83 93 0.116325785 71.50469526 96.34332368 88 2 67 83 93 0.116325785 71.50469526 96.34332368 89 3 67 83 93 0.116325785 71.50469526 96.34332368 93 ... ... ... ... ... ... ... ... 5107 67 83 93 0.116325785 71.50469526 96.34332368 90 5108 67 83 93 0.116325785 71.50469526 96.34332368 87 5109 67 83 93 0.116325785 71.50469526 96.34332368 93","title":"Curve Number Table"},{"location":"quickstart/#final-events-table","text":"Final events to be modeled. hours E0001 E0002 E0003 ... E0395 E0396 E0397 E0398 E0399 0 0 0 0 ... 0 0 0 0 0 0.5 0.010 0.0047 0.0030 ... 0.01359 0.01038 0.00674 0.00234 0.00555 1 0.013 0.00948 0.0043 ... 0.0447 0.0584 0.0124 0.00356 0.008906 1.5 0.10 0.067680 0.0294 ... 0.1660 0.15102 0.1220 0.0198 0.0433 ... ... ... ... ... ... ... ... ... ... 22 0.13 0.1534 0.0807 ... 0.1878 0.1707 0.234 0.07389 0.149328 23.5 0.103 0.21576 0.14100 ... 0.1373 0.1408 0.317 0.15162 0.221391 24 0.08732 0.25004 0.1836 ... 0.1132 0.1293 0.3403 0.2053 0.2430","title":"Final Events Table"},{"location":"quickstart/#event-weight-table","text":"Weight E0001 0.006207654 E0002 0.005313752 ... ... E0964 0.000019172 E0965 0.000071544","title":"Event Weight Table"},{"location":"quickstart/#metada","text":"Additional data developed in intermediated calculations included for traceability/reporducibility. [{ # Run Data (Event_Duration_Quartile_Decile_CurveNumber) 'RunInfo': {'E60001': 'E1_6Hr_Q1_D10_CN79', 'E60002': 'E2_6Hr_Q1_D90_CN78', ...} # Cumulative (raw) precipitation time-series 'precip': {'E60001': {'0.0': 0.0, '0.5': 0.8010830472988398, '1.0': 1.4541398793359375, '1.5': 1.8372665541310351, '2.0': 2.057129020916858, '2.5': 2.1550875457224223, '3.0': 2.170325538469955, '3.5': 2.176856106790326, '4.0': 2.176856106790326, '4.5': 2.176856106790326, '5.0': 2.176856106790326, '5.5': 2.176856106790326, '6.0': 2.176856106790326}, 'E60002': { ... } # Cumulative excess-precipitation time-series 'cum_excess': {'E60001': {'0.0': 0.0, '0.5': 0.02479673948334961, '1.0': 0.23766036959891948, '1.5': 0.4300482251417235, '2.0': 0.5562285716308201, '2.5': 0.6155457935761868, '3.0': 0.6249312656222388, '3.5': 0.6289662984090281, '4.0': 0.6289662984090281, '4.5': 0.6289662984090281, '5.0': 0.6289662984090281, '5.5': 0.6289662984090281, '6.0': 0.6289662984090281}, 'E60002': { ... } # Incremental excess-precipitation time-series 'incr_excess' {'E60001': {'0.0': 0.0, '0.5': 0.02479673948334961, '1.0': 0.21286363011556986, '1.5': 0.19238785554280402, '2.0': 0.1261803464890966, '2.5': 0.059317221945366705, '3.0': 0.009385472046052001, '3.5': 0.004035032786789294, '4.0': 0.0, '4.5': 0.0, '5.0': 0.0, '5.5': 0.0, '6.0': 0.0}, 'E60002': { ... } # Curve groups (similar excess-precipitation time-series) 'groups' {'E0001': ['E60002', 'E60930', 'E60551', ... , E64421', E64423', 'E64483'], 'E0002': [... ] } # Test Statistic 'test_stat' {'E0001': [0.235358, 0.251304, 0.214125, ... 0.18715, 0.184935, 0.174473], 'E0002': [... ] }]","title":"Metada"},{"location":"setup/","text":"Setup Visit jupyter for instructions on setting up computational environment. For installation of python libraries on Windows operating system, we recommend using wheels developed by Christoph Gohlke . Required libraries and suggested versions: Library Version fiona 1.8.4 geopandas 0.4.0 matplotlib 3.0.2 nbconvert 5.5.0 nptyping 0.2.0 numpy 1.16.3 pandas 0.24.2 papermill 1.0.0 pathlib2 2.3.3 pyproj 1.9.6 pytables 3.4.4 python 3.7.1 rasterio 1.0.13 scipy 1.1.0 scrapbook 0.2.0 urllib3 1.24.1","title":"Setup"},{"location":"setup/#setup","text":"Visit jupyter for instructions on setting up computational environment. For installation of python libraries on Windows operating system, we recommend using wheels developed by Christoph Gohlke . Required libraries and suggested versions: Library Version fiona 1.8.4 geopandas 0.4.0 matplotlib 3.0.2 nbconvert 5.5.0 nptyping 0.2.0 numpy 1.16.3 pandas 0.24.2 papermill 1.0.0 pathlib2 2.3.3 pyproj 1.9.6 pytables 3.4.4 python 3.7.1 rasterio 1.0.13 scipy 1.1.0 scrapbook 0.2.0 urllib3 1.24.1","title":"Setup"}]}