{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Theoretical Recurrence Interval\n",
        "\n",
        "__Description__:\n",
        "\n",
        "__Input__: \n",
        "\n",
        "__Output__: \n",
        "\n",
        "---\n",
        "## Load Libraries, Parameters, and File Paths:\n",
        "### Libraries:"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pathlib as pl\n",
        "from matplotlib import pyplot as plt"
      ],
      "outputs": [],
      "execution_count": 1,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Parameters:\n",
        "#### Site specific:"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "Project_Area = 'Sacramento'\n",
        "\n",
        "#root_dir = pl.Path(os.getcwd())\n",
        "root_dir = pl.Path(r'C:\\Users\\sputnam\\Desktop\\PFRA_Production\\Pluvial\\Sacramento\\Efficiency70')\n",
        "outputs_dir = root_dir/'Outputs'"
      ],
      "outputs": [],
      "execution_count": 2,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Project specific (global):"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "binwidth = 0.1       # [inches]; increment for binning the excess rainfall amount\n",
        "RI_max = 3000\n",
        "\n",
        "verbose = True        # Option to display print statements\n",
        "display_plots = True  # Option to display plots"
      ],
      "outputs": [],
      "execution_count": 3,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### File Paths:\n",
        "#### Weights:"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "weight_files = []\n",
        "for f in outputs_dir.glob('*.json'):\n",
        "    if 'Weights' in f.stem and 'TRI' not in f.stem: \n",
        "        weight_files.append(f)       \n",
        "        print(f)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "C:\\Users\\sputnam\\Desktop\\PFRA_Production\\Pluvial\\Sacramento\\Efficiency70\\Outputs\\Sacramento_P01_D30_Weights.json\n",
            "C:\\Users\\sputnam\\Desktop\\PFRA_Production\\Pluvial\\Sacramento\\Efficiency70\\Outputs\\Sacramento_P02_D15_Weights.json\n",
            "C:\\Users\\sputnam\\Desktop\\PFRA_Production\\Pluvial\\Sacramento\\Efficiency70\\Outputs\\Sacramento_P03_D37_Weights.json\n"
          ]
        }
      ],
      "execution_count": 4,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Forcing:"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "forcing_files = []\n",
        "for f in outputs_dir.glob('**/*.json'):\n",
        "    if 'Forcing' in f.parent.stem:\n",
        "        forcing_files.append(f)\n",
        "        print(f)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "C:\\Users\\sputnam\\Desktop\\PFRA_Production\\Pluvial\\Sacramento\\Efficiency70\\Outputs\\Sacramento_P01_Forcing\\Sacramento_P01_D23.json\n",
            "C:\\Users\\sputnam\\Desktop\\PFRA_Production\\Pluvial\\Sacramento\\Efficiency70\\Outputs\\Sacramento_P01_Forcing\\Sacramento_P01_D24.json\n",
            "C:\\Users\\sputnam\\Desktop\\PFRA_Production\\Pluvial\\Sacramento\\Efficiency70\\Outputs\\Sacramento_P01_Forcing\\Sacramento_P01_D25.json\n",
            "C:\\Users\\sputnam\\Desktop\\PFRA_Production\\Pluvial\\Sacramento\\Efficiency70\\Outputs\\Sacramento_P01_Forcing\\Sacramento_P01_D26.json\n",
            "C:\\Users\\sputnam\\Desktop\\PFRA_Production\\Pluvial\\Sacramento\\Efficiency70\\Outputs\\Sacramento_P01_Forcing\\Sacramento_P01_D27.json\n",
            "C:\\Users\\sputnam\\Desktop\\PFRA_Production\\Pluvial\\Sacramento\\Efficiency70\\Outputs\\Sacramento_P01_Forcing\\Sacramento_P01_D28.json\n",
            "C:\\Users\\sputnam\\Desktop\\PFRA_Production\\Pluvial\\Sacramento\\Efficiency70\\Outputs\\Sacramento_P01_Forcing\\Sacramento_P01_D29.json\n",
            "C:\\Users\\sputnam\\Desktop\\PFRA_Production\\Pluvial\\Sacramento\\Efficiency70\\Outputs\\Sacramento_P01_Forcing\\Sacramento_P01_D30.json\n",
            "C:\\Users\\sputnam\\Desktop\\PFRA_Production\\Pluvial\\Sacramento\\Efficiency70\\Outputs\\Sacramento_P01_Forcing\\Sacramento_P01_D31.json\n",
            "C:\\Users\\sputnam\\Desktop\\PFRA_Production\\Pluvial\\Sacramento\\Efficiency70\\Outputs\\Sacramento_P01_Forcing\\Sacramento_P01_D32.json\n",
            "C:\\Users\\sputnam\\Desktop\\PFRA_Production\\Pluvial\\Sacramento\\Efficiency70\\Outputs\\Sacramento_P01_Forcing\\Sacramento_P01_D33.json\n",
            "C:\\Users\\sputnam\\Desktop\\PFRA_Production\\Pluvial\\Sacramento\\Efficiency70\\Outputs\\Sacramento_P01_Forcing\\Sacramento_P01_D34.json\n",
            "C:\\Users\\sputnam\\Desktop\\PFRA_Production\\Pluvial\\Sacramento\\Efficiency70\\Outputs\\Sacramento_P01_Forcing\\Sacramento_P01_D35.json\n",
            "C:\\Users\\sputnam\\Desktop\\PFRA_Production\\Pluvial\\Sacramento\\Efficiency70\\Outputs\\Sacramento_P02_Forcing\\Sacramento_P02_D01.json\n",
            "C:\\Users\\sputnam\\Desktop\\PFRA_Production\\Pluvial\\Sacramento\\Efficiency70\\Outputs\\Sacramento_P02_Forcing\\Sacramento_P02_D02.json\n",
            "C:\\Users\\sputnam\\Desktop\\PFRA_Production\\Pluvial\\Sacramento\\Efficiency70\\Outputs\\Sacramento_P02_Forcing\\Sacramento_P02_D03.json\n",
            "C:\\Users\\sputnam\\Desktop\\PFRA_Production\\Pluvial\\Sacramento\\Efficiency70\\Outputs\\Sacramento_P02_Forcing\\Sacramento_P02_D04.json\n",
            "C:\\Users\\sputnam\\Desktop\\PFRA_Production\\Pluvial\\Sacramento\\Efficiency70\\Outputs\\Sacramento_P02_Forcing\\Sacramento_P02_D05.json\n",
            "C:\\Users\\sputnam\\Desktop\\PFRA_Production\\Pluvial\\Sacramento\\Efficiency70\\Outputs\\Sacramento_P02_Forcing\\Sacramento_P02_D06.json\n",
            "C:\\Users\\sputnam\\Desktop\\PFRA_Production\\Pluvial\\Sacramento\\Efficiency70\\Outputs\\Sacramento_P02_Forcing\\Sacramento_P02_D07.json\n",
            "C:\\Users\\sputnam\\Desktop\\PFRA_Production\\Pluvial\\Sacramento\\Efficiency70\\Outputs\\Sacramento_P02_Forcing\\Sacramento_P02_D08.json\n",
            "C:\\Users\\sputnam\\Desktop\\PFRA_Production\\Pluvial\\Sacramento\\Efficiency70\\Outputs\\Sacramento_P02_Forcing\\Sacramento_P02_D09.json\n",
            "C:\\Users\\sputnam\\Desktop\\PFRA_Production\\Pluvial\\Sacramento\\Efficiency70\\Outputs\\Sacramento_P02_Forcing\\Sacramento_P02_D10.json\n",
            "C:\\Users\\sputnam\\Desktop\\PFRA_Production\\Pluvial\\Sacramento\\Efficiency70\\Outputs\\Sacramento_P02_Forcing\\Sacramento_P02_D11.json\n",
            "C:\\Users\\sputnam\\Desktop\\PFRA_Production\\Pluvial\\Sacramento\\Efficiency70\\Outputs\\Sacramento_P02_Forcing\\Sacramento_P02_D12.json\n",
            "C:\\Users\\sputnam\\Desktop\\PFRA_Production\\Pluvial\\Sacramento\\Efficiency70\\Outputs\\Sacramento_P02_Forcing\\Sacramento_P02_D13.json\n",
            "C:\\Users\\sputnam\\Desktop\\PFRA_Production\\Pluvial\\Sacramento\\Efficiency70\\Outputs\\Sacramento_P02_Forcing\\Sacramento_P02_D14.json\n",
            "C:\\Users\\sputnam\\Desktop\\PFRA_Production\\Pluvial\\Sacramento\\Efficiency70\\Outputs\\Sacramento_P02_Forcing\\Sacramento_P02_D15.json\n",
            "C:\\Users\\sputnam\\Desktop\\PFRA_Production\\Pluvial\\Sacramento\\Efficiency70\\Outputs\\Sacramento_P02_Forcing\\Sacramento_P02_D16.json\n",
            "C:\\Users\\sputnam\\Desktop\\PFRA_Production\\Pluvial\\Sacramento\\Efficiency70\\Outputs\\Sacramento_P02_Forcing\\Sacramento_P02_D17.json\n",
            "C:\\Users\\sputnam\\Desktop\\PFRA_Production\\Pluvial\\Sacramento\\Efficiency70\\Outputs\\Sacramento_P02_Forcing\\Sacramento_P02_D18.json\n",
            "C:\\Users\\sputnam\\Desktop\\PFRA_Production\\Pluvial\\Sacramento\\Efficiency70\\Outputs\\Sacramento_P02_Forcing\\Sacramento_P02_D19.json\n",
            "C:\\Users\\sputnam\\Desktop\\PFRA_Production\\Pluvial\\Sacramento\\Efficiency70\\Outputs\\Sacramento_P02_Forcing\\Sacramento_P02_D20.json\n",
            "C:\\Users\\sputnam\\Desktop\\PFRA_Production\\Pluvial\\Sacramento\\Efficiency70\\Outputs\\Sacramento_P02_Forcing\\Sacramento_P02_D21.json\n",
            "C:\\Users\\sputnam\\Desktop\\PFRA_Production\\Pluvial\\Sacramento\\Efficiency70\\Outputs\\Sacramento_P02_Forcing\\Sacramento_P02_D22.json\n",
            "C:\\Users\\sputnam\\Desktop\\PFRA_Production\\Pluvial\\Sacramento\\Efficiency70\\Outputs\\Sacramento_P03_Forcing\\Sacramento_P03_D36.json\n",
            "C:\\Users\\sputnam\\Desktop\\PFRA_Production\\Pluvial\\Sacramento\\Efficiency70\\Outputs\\Sacramento_P03_Forcing\\Sacramento_P03_D37.json\n",
            "C:\\Users\\sputnam\\Desktop\\PFRA_Production\\Pluvial\\Sacramento\\Efficiency70\\Outputs\\Sacramento_P03_Forcing\\Sacramento_P03_D38.json\n",
            "C:\\Users\\sputnam\\Desktop\\PFRA_Production\\Pluvial\\Sacramento\\Efficiency70\\Outputs\\Sacramento_P03_Forcing\\Sacramento_P03_D39.json\n",
            "C:\\Users\\sputnam\\Desktop\\PFRA_Production\\Pluvial\\Sacramento\\Efficiency70\\Outputs\\Sacramento_P03_Forcing\\Sacramento_P03_D40.json\n",
            "C:\\Users\\sputnam\\Desktop\\PFRA_Production\\Pluvial\\Sacramento\\Efficiency70\\Outputs\\Sacramento_P03_Forcing\\Sacramento_P03_D41.json\n",
            "C:\\Users\\sputnam\\Desktop\\PFRA_Production\\Pluvial\\Sacramento\\Efficiency70\\Outputs\\Sacramento_P03_Forcing\\Sacramento_P03_D42.json\n"
          ]
        }
      ],
      "execution_count": 5,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## Calculate the Theoretical Recurrence Interval:"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "updated_list = []\n",
        "lst = ['D30', 'D15', 'D37']\n",
        "for forcing_file in forcing_files:\n",
        "    for d in lst:\n",
        "        if d in forcing_file.stem:\n",
        "            updated_list.append(forcing_file)\n",
        "updated_list            "
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 12,
          "data": {
            "text/plain": [
              "[WindowsPath('C:/Users/sputnam/Desktop/PFRA_Production/Pluvial/Sacramento/Efficiency70/Outputs/Sacramento_P01_Forcing/Sacramento_P01_D30.json'),\n",
              " WindowsPath('C:/Users/sputnam/Desktop/PFRA_Production/Pluvial/Sacramento/Efficiency70/Outputs/Sacramento_P02_Forcing/Sacramento_P02_D15.json'),\n",
              " WindowsPath('C:/Users/sputnam/Desktop/PFRA_Production/Pluvial/Sacramento/Efficiency70/Outputs/Sacramento_P03_Forcing/Sacramento_P03_D37.json')]"
            ]
          },
          "metadata": {}
        }
      ],
      "execution_count": 12,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "dic = {}\n",
        "dic_vol = {}\n",
        "mods = []\n",
        "doms = []\n",
        "tris = []\n",
        "small = []\n",
        "first = []\n",
        "large =  []\n",
        "for forcing_file in updated_list:\n",
        "    \n",
        "    _, Pluvial_Model, Domain = forcing_file.stem.split('_')\n",
        "    mods.append(Pluvial_Model)\n",
        "    doms.append(Domain)\n",
        "    \n",
        "    for w in weight_files:\n",
        "        if Pluvial_Model in w.stem:\n",
        "            weight_file = w\n",
        "            \n",
        "    with open(forcing_file) as f:\n",
        "            ff_dic =  json.load(f)\n",
        "    \n",
        "    with open(weight_file) as f:\n",
        "            wt =  json.load(f)  \n",
        "            \n",
        "    mainBCN = list(wt['BCName'].keys())[0]\n",
        "    \n",
        "    df = pd.DataFrame()\n",
        "    df['Events'] = list(wt['BCName'][mainBCN].keys())\n",
        "    df['Weight'] = list(wt['BCName'][mainBCN].values())    \n",
        "    df = df.set_index('Events')\n",
        "    for d in list(ff_dic.keys()):\n",
        "        for k, v in ff_dic[d]['BCName'][Domain].items():\n",
        "            df.loc[k, 'Volume'] = sum(v)\n",
        "            df.loc[k, 'Dur'] = d\n",
        "    df = df.reset_index().sort_values(by=['Volume'], ascending = True).set_index('Events') \n",
        "    \n",
        "    small.append(df[df['Volume']==min(df['Volume'])].index[0])\n",
        "    first.append(df[df['Volume']==min(df[df['Volume']>0]['Volume'])].index[0])\n",
        "    large.append(df[df['Volume']==max(df['Volume'])].index[0])\n",
        "    \n",
        "    binmin = min(df['Volume'])\n",
        "    binmax = max(df['Volume'])\n",
        "    bins = np.arange(binmin, binmax+binwidth, binwidth)\n",
        "    \n",
        "    lst = []\n",
        "    for i, b in enumerate(bins[:]):\n",
        "        if i==0:\n",
        "            weight = sum(df[(0.0 == df['Volume'])]['Weight'])\n",
        "        else:\n",
        "            weight = sum(df[(bins[i-1]  < df['Volume']) & (df['Volume']<=b)]['Weight'])\n",
        "        lst.append((b, weight))\n",
        "    \n",
        "    binned  = pd.DataFrame()\n",
        "    binned['Volume'] = [i[0] for i in lst]\n",
        "    binned['Weight'] = [i[1] for i in lst]\n",
        "    binned['Cumulative'] = binned['Weight'].cumsum()\n",
        "    binned['Theoretical RI'] = 1.0/(0.5-binned['Cumulative'])\n",
        "    \n",
        "    TTRI = binned.loc[0]['Theoretical RI']\n",
        "    tris.append(TTRI)\n",
        "    \n",
        "    if verbose:\n",
        "        print('{0} {1} Theoretical Threshold RI: {2} years'.format(Pluvial_Model, Domain, TTRI))\n",
        "        \n",
        "    vavg = []\n",
        "    for i, b in enumerate(binned['Volume']):\n",
        "        if i==0:\n",
        "            vavg.append(b)\n",
        "        elif i>0:\n",
        "            vavg.append((b+binned['Volume'][i-1])/2)\n",
        "    binned['Vavg'] = vavg \n",
        "    \n",
        "    event = []\n",
        "    for vavg in binned['Vavg']:\n",
        "        diff = df['Volume']-vavg\n",
        "        event.append(diff[diff.abs().argsort()].index[0])\n",
        "    binned['Event'] = event    \n",
        "    binned.head()\n",
        "    \n",
        "    unique_events = list(set(list(binned['Event'])))\n",
        "    edf = pd.DataFrame(data = {'Event': unique_events})\n",
        "    for i, e in enumerate(edf['Event']):\n",
        "        edf.loc[i, 'Weight'] = sum(binned[binned['Event']==e]['Weight']) \n",
        "        edf.loc[i, 'Volume'] = df.loc[e]['Volume']\n",
        "    edf = edf[edf['Weight']>0.0].copy(deep=True)\n",
        "    assert np.round(sum(edf['Weight']), 2) == 0.5 , 'Total weight does not equal 0.5 as expected'\n",
        "    edf = edf.sort_values('Volume').reset_index(drop = True)\n",
        "    edf['Cumulative'] = edf['Weight'].cumsum()\n",
        "    print('Simulations to include in the Global Scale Test: {}'.format(edf.shape[0]))\n",
        "    \n",
        "    #fig, ax = plt.subplots(2, 1, figsize=(18, 12))\n",
        "    #ax[0].plot(df['Weight'], df['Volume'], linestyle = '', marker = '.' , label = 'All Events', color = 'gray', alpha = 0.75)\n",
        "    #ax[0].plot(edf['Weight'], edf['Volume'], linestyle = '', marker = '.', color = 'blue', label = 'Subset')\n",
        "    #ax[0].set_xlabel('Weight, [-]', fontsize = 10)\n",
        "    #ax[0].set_ylabel('Excess Rainfall, [inches]', fontsize=10)\n",
        "    #ax[0].set_xlim([0, 0.002])\n",
        "    #ax[0].legend()\n",
        "    #ax[0].grid()    \n",
        "    #ax[1].plot(binned['Volume'], 0.5 - binned['Cumulative'], linestyle = '-', marker = '', label = 'All Events', color = 'gray', alpha = 0.75)\n",
        "    #ax[1].plot(edf['Volume'], 0.5-edf['Cumulative'], linestyle = '-', marker = '', color = 'blue', label = 'Subset')\n",
        "    #ax[1].set_xlabel('Excess Rainfall, [inches]', fontsize = 10)\n",
        "    #ax[1].set_ylabel('Weight (~ probability)', fontsize=10)\n",
        "    #ax[1].legend()\n",
        "    #ax[1].grid()       \n",
        "    \n",
        "    edic = {'BCName':{mainBCN:{}}}\n",
        "    elist =  []\n",
        "    for i, e in enumerate(edf['Event']):\n",
        "        edic['BCName'][mainBCN][e] = edf.loc[i]['Weight']\n",
        "        elist.append(e)\n",
        "    #with open(outputs_dir/'{0}_{1}_{2}_Weights_TRI.json'.format(Project_Area, Pluvial_Model, Domain), 'w') as f:\n",
        "    #    json.dump(edic, f)\n",
        "        \n",
        "    df = pd.DataFrame(data = {'Events': elist})\n",
        "    df = df.set_index('Events')\n",
        "    df.to_csv(outputs_dir/'{0}_{1}_{2}_Events_TRI.csv'.format(Project_Area, Pluvial_Model, Domain))    \n",
        "#tri_df = pd.DataFrame(data = {'Model': mods, 'Domain': doms, 'TRI': tris})    \n",
        "#tri_df = tri_df.set_index('Model')\n",
        "#tri_df.to_csv(outputs_dir/'{0}_TRI.csv'.format(Project_Area))  \n",
        "scale1_df = pd.DataFrame(data = {'Model': mods, 'Domain': doms, 'Smallest': small, 'First': first, 'Largest': large})    \n",
        "scale1_df = scale1_df.set_index('Model')\n",
        "scale1_df.to_csv(outputs_dir/'{0}_scale1.csv'.format(Project_Area))  "
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "P01 D30 Theoretical Threshold RI: 27.40087824732952 years\n",
            "Simulations to include in the Global Scale Test: 49\n",
            "P02 D15 Theoretical Threshold RI: 47.423768742270745 years\n",
            "Simulations to include in the Global Scale Test: 33\n",
            "P03 D37 Theoretical Threshold RI: 24.673799958892097 years\n",
            "Simulations to include in the Global Scale Test: 45\n"
          ]
        }
      ],
      "execution_count": 37,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## End"
      ],
      "metadata": {}
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python3"
    },
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.1",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "nteract": {
      "version": "0.15.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}