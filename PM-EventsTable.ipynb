{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Libraries and Parameters:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('core')\n",
    "import hydromet_reduced\n",
    "from hydromet import*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specify parameters: \n",
    "- Shared parameters needed for running the EventsTable.ipynb and the reEventsTable.ipynb."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Filenames and paths:\n",
    "Project_Area = 'Sacramento'\n",
    "Pluvial_Model = 'P02'          \n",
    "BCN = 'D15'    \n",
    "pluvial_params = '{0}_{1}_Pluvial_Parameters.xlsx'.format(Project_Area, Pluvial_Model)  # Not required if curve number is manually set below\n",
    "\n",
    "root_dir = pl.Path(r'C:\\Users\\sputnam\\Desktop\\PFRA_Production\\Sacramento')\n",
    "#root_dir = pl.Path(os.getcwd())\n",
    "inputs_dir = root_dir/'Inputs'\n",
    "outputs_dir = root_dir/'Outputs'\n",
    "notebook_dir = root_dir/'Notebooks'\n",
    "pluvial_params_dir = inputs_dir/pluvial_params  # Not required if curve number is manually set below\n",
    "\n",
    "\n",
    "## Options:\n",
    "seed = 287 # np.random.randint(low=0, high=10000)\n",
    "display_plots = True\n",
    "display_print = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A. Run EventsTable Notebook:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specify parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Excess rainfall parameters:\n",
    "#CN = 80                      # Curve number\n",
    "#volume = 2                   # NOAA Atlas 14 volume\n",
    "#region = 1                   # NOAA Atlas 14 region\n",
    "durations = [6, 12, 24, 96]  # Calculate multiple durations \n",
    "#durations = [6]             # Calcuate a single duration\n",
    "\n",
    "\n",
    "## Grouping parameters:\n",
    "tempEpsilon_dic = {'6': 1, '12': 2, '24': 4, '96': 16} \n",
    "tempEpsilon2_dic = {'6': 0.5, '12': 1, '24': 2, '96': 8}\n",
    "convEpsilon_dic = {'6': 150, '12': 155.56, '24': 163.64, '96': 155.56}\n",
    "volEpsilon_dic = {'6': 66.67, '12': 66.67, '24': 66.67, '96': 66.67}\n",
    "\n",
    "\n",
    "## Filenames and paths:\n",
    "precip_table = '{0}_{1}_{2}_PrecipTable.xlsx'.format(Project_Area, Pluvial_Model, BCN) \n",
    "\n",
    "precip_table_dir = outputs_dir/precip_table\n",
    "datarepository_dir = pl.Path(os.getcwd())/'DataRepository'\n",
    "bin_dir = pl.Path(os.getcwd())/'bin'\n",
    "#datarepository_dir = root_dir/'DataRepository'\n",
    "#bin_dir = root_dir/'bin'\n",
    "\n",
    "\n",
    "## Options:\n",
    "save_dss = False\n",
    "remove_ind_dur = True #Remove individual duration files which are combined at the end of this notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Randomly selected seed: {0}\".format(seed))\n",
    "\n",
    "if not os.path.exists(notebook_dir): os.mkdir(notebook_dir)\n",
    "    \n",
    "nb_executed = {}\n",
    "\n",
    "for dur in durations:\n",
    "    nb_executed[str(dur)] = str(notebook_dir/'EventsTable_{0}_{1}_{2}_Dur{3}_tempE{4}_{5}_convE{6}_volE{7}.ipynb'.format(Project_Area, Pluvial_Model, BCN, dur, \n",
    "                                                                                                                         tempEpsilon_dic[str(dur)], tempEpsilon2_dic[str(dur)],\n",
    "                                                                                                                         convEpsilon_dic[str(dur)], volEpsilon_dic[str(dur)]))\n",
    "    print(nb_executed[str(dur)])\n",
    "    \n",
    "    nb_parameters = {'duration': dur, 'tempEpsilon': tempEpsilon_dic[str(dur)], 'tempEpsilon2': tempEpsilon2_dic[str(dur)], 'convEpsilon': convEpsilon_dic[str(dur)],\n",
    "                       'volEpsilon': volEpsilon_dic[str(dur)], 'BCN': BCN, 'inputs_dir': str(inputs_dir), 'precip_table_dir': str(precip_table_dir), \n",
    "                       'datarepository_dir': str(datarepository_dir), 'bin_dir': str(bin_dir), 'outputs_dir': str(outputs_dir), 'seed': seed,\n",
    "                       'display_plots': display_plots, 'display_print': display_print,'save_dss': save_dss}\n",
    "    \n",
    "    if 'CN' not in locals() and 'volume' not in locals():\n",
    "        nb_parameters['pluvial_params_dir'] = str(pluvial_params_dir)\n",
    "    elif 'CN' not in locals():\n",
    "        nb_parameters['pluvial_params_dir'] = str(pluvial_params_dir)\n",
    "        nb_parameters['volume'] = volume  \n",
    "        nb_parameters['region'] = region   \n",
    "    elif 'volume' not in locals(): \n",
    "        nb_parameters['CN'] = CN  \n",
    "    \n",
    "    pm.execute_notebook('EventsTable.ipynb', nb_executed[str(dur)], parameters = nb_parameters);\n",
    "    \n",
    "    nb = nb_executed[str(dur)]\n",
    "    ! jupyter nbconvert $nb --log-level WARN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display the results:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Open the executed notebook and extract the scraps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_reduction_dic = {}\n",
    "\n",
    "for dur in durations:\n",
    "    nb = sb.read_notebook(nb_executed[str(dur)])\n",
    "    final_reduction_dic[str(dur)] = nb.scraps['final_reduction_lst'][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Final incremental excess rainfall results (combined events):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dur in durations:\n",
    "    print(\"Number of curves reduced by {0}% or {1} curves out of {2} remaining\".format(np.round(final_reduction_dic[str(dur)][0], 2), final_reduction_dic[str(dur)][1], final_reduction_dic[str(dur)][2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine the results for all durations and save:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Excess rainfall:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "excess_dic = combine_results('Excess_Rainfall', outputs_dir, BCN, durations, tempEpsilon_dic, convEpsilon_dic, volEpsilon_dic, BCN, remove_ind_dur)\n",
    "\n",
    "with open(outputs_dir/'{0}_{1}_{2}.json'.format(Project_Area, Pluvial_Model, BCN), 'w') as f:\n",
    "    json.dump(excess_dic, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Event weights:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_dic = combine_results('Weights', outputs_dir, BCN, durations, tempEpsilon_dic, convEpsilon_dic, volEpsilon_dic, BCN, remove_ind_dur)\n",
    "\n",
    "with open(outputs_dir/'{0}_{1}_{2}_Weights.json'.format(Project_Area, Pluvial_Model, BCN), 'w') as f:\n",
    "    json.dump(weights_dic, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Metadata:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = combine_metadata(outputs_dir, BCN, durations, tempEpsilon_dic, convEpsilon_dic, volEpsilon_dic, BCN, remove_ind_dur)\n",
    "\n",
    "with open(outputs_dir/'{0}_{1}_{2}_Metadata.json'.format(Project_Area, Pluvial_Model, BCN), 'w') as f:\n",
    "    json.dump(metadata, f)       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QC the combined results:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot the weight versus the total runoff for each group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_amount_vs_weight(weights_dic, excess_dic, BCN, BCN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B. Run reEventsTable Notebook:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check if the pluvial domain has stormwater infrastructure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_reduced = checkif_SWinfra(pluvial_params_dir, BCN, display_print)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### If it does, run the notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if run_reduced == 'YES':\n",
    "    reEventsTable = str(notebook_dir/'reEventsTable_{0}_{1}_{2}.ipynb'.format(Project_Area, Pluvial_Model, BCN))\n",
    "                                                                                                                 \n",
    "    nb_parameters = {'Project_Area': Project_Area,'Pluvial_Model': Pluvial_Model, 'BCN': BCN, 'pluvial_params_dir': str(pluvial_params_dir),\n",
    "                     'outputs_dir': str(outputs_dir), 'display_plots': display_plots, 'display_print': display_print}\n",
    "    \n",
    "    pm.execute_notebook('reEventsTable.ipynb', reEventsTable, parameters = nb_parameters);\n",
    "    \n",
    "    ! jupyter nbconvert $reEventsTable --log-level WARN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save a Copy of this Notebook:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### File save this notebook and then run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_nb = 'PM-EventsTable'\n",
    "new_nb = '{0}_{1}_{2}_{3}.ipynb'.format(orig_nb, Project_Area, Pluvial_Model, BCN)\n",
    "new_nb_path = str(notebook_dir/new_nb)\n",
    "\n",
    "shutil.copy(pl.Path(os.getcwd())/'{0}.ipynb'.format(orig_nb), new_nb_path)\n",
    "\n",
    "! jupyter nbconvert $new_nb_path --log-level WARN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
